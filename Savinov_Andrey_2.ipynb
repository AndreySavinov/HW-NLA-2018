{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2 \n",
    "\n",
    "## 155 pts\n",
    "\n",
    "## For problems 1, 2, 4: all functions that you are asked to implement, you have to complete in separate file ```pset2.py```, where we provide signatures of the required functions . Also only this ```py```-file you have to submit in the bot to check correctness of your implementations.\n",
    "\n",
    "## For problem 3: see instructions in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (LU decomposition) 35 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LU for band matrices \n",
    "\n",
    "The complexity to find an LU decomposition of a dense $n\\times n$ matrix is $\\mathcal{O}(n^3)$.\n",
    "Significant reduction in complexity can be achieved if the matrix has a certain structure, e.g. it is sparse. \n",
    "In the following task we consider an important example of $LU$ for a special type of sparse matrices –– band matrices with the bandwidth $m$ equal to 3 or 5 which called tridiagonal and pentadiagonal respectively.\n",
    "\n",
    "- (5 pts) Write a function ```band_lu(diag_broadcast, n)``` which computes LU decomposition for tridiagonal or pentadiagonal matrix with given diagonal values. \n",
    "For example, input parametres ```(diag_broadcast = [1,-2,1], n = 4)``` mean that we need to find LU decomposition for the triangular matrix of the form:\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "-2 & 1 & 0 & 0\\\\\n",
    "1 & -2 & 1 & 0 \\\\\n",
    "0 & 1 & -2 & 1 \\\\\n",
    "0 & 0 & 1 & -2 \\\\\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "As an output it is considered to make ```L``` and ```U``` - 2D arrays representing diagonals in factors $L$ (```L[0]``` keeps first lower diagonal, ```L[1]``` keeps second lower, ...), and $U$ (```U[:,0]``` keeps main diagonal, ```U[:,1]``` keeps first upper, ...). More details you can find in comments to the corresponding function in ```pset2.py``` \n",
    "- (2 pts) Compare execution time of the band LU decomposition using standard function from ```scipy```, i.e. which takes the whole matrix and does not know about its special structure, and band decomposition of yours implementation. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 4.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "25.8 s ± 514 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Implement function in the ```pset2.py``` file\n",
    "from pset2 import band_lu\n",
    "from scipy.sparse import diags # can be used with broadcasting of scalars if desired dimensions are large\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# Your code is here\n",
    "diag_self = np.array([1, -2, -1])\n",
    "%timeit band_lu(diag_self, 10000)\n",
    "\n",
    "diag_embedded = diags([np.ones(9999), -2*np.ones(10000), np.ones(9999)], [-1,0,1]).toarray() \n",
    "%timeit lu(diag_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution to sparse matrix is much faster because it accounts for matrix structure. And embedded function does standart Gaussian elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Completing the proof of existence of LU \n",
    "\n",
    "Some details in lecture proofs about $LU$ were omitted. Let us complete them here.\n",
    "- (5 pts) Prove that if $LU$ decomposition exists, then matrix is strictly regular.\n",
    "- (5 pts) Prove that if $A$ is a strictly regular matrix, then $A_1 = D - \\frac 1a b c^T$ (see lectures for notations) is also strictly regular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My solution is here\n",
    "\n",
    "- Since non-singularity of triangular matrices is equivalent to the fact that their diagonal elements are not equal to zero. \n",
    "$\\det A = \\det L \\det U \\ne 0$. To obtain minor $M_{n-1}$ let's multiply first $n-1$ rows of matrix $L$ and first $n-1$ columns of martix $U$. Elements of the last column of matrix $L$  are equal to zero and elements of the last row of matrix $U$ are equal to zero excepted the last elements of row and column respectively. That's why to obtain minor $M_{n-1}$ we can multiply matrices $L_{n-1}$ and  $U_{n-1}$ which are obtained fron $L$ and $U$ by deleting last row and last column. $\\det M_{n-1} = \\det L_{n-1} \\det U_{n-1}\\ne 0$, because diagonal elements of $L_{n-1}$ and $U_{n-1}$ are not equal to zero. Let's continue to apply this procedure to $M_{n-2}$ and so further. As a result, determinant of all principle minors is not equal to zero, that's why matrix is strictly regular.\n",
    "\n",
    "- $$\n",
    "    A = \\begin{pmatrix}\n",
    "          a & c^{\\top} \\\\\n",
    "          b & D\n",
    "    \\end{pmatrix},\n",
    "$$\n",
    "where $D$ is $(n-1) \\times (n-1)$.\n",
    "\n",
    "$$\n",
    "     S =\\begin{pmatrix}\n",
    "     1 & 0 \\\\\n",
    "     -z & I\n",
    "     \\end{pmatrix}, \\:\\:\\: z = \\frac{b}{a}\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "     A_{new} = \\begin{pmatrix}\n",
    "     a & c^{\\top} \\\\\n",
    "     0 & A_1\n",
    "     \\end{pmatrix},\n",
    "$$\n",
    "$$\n",
    " A_1 = D - \\frac 1a b c^T\n",
    "$$\n",
    "$$\n",
    "  A_{new} = SA \\: \\: \\det A_{new} = \\det S \\det A =  \\det A = a \\det A_1 \\ne 0, \\:\\: a \\ne 0 \\: because \\: A\\: -\\: strictly\\: regular.\\: Then\\: \\det A_1 \\ne 0 \n",
    "$$\n",
    " Let's apply the same procedure for matrix $A_1 = \\begin{pmatrix}\n",
    "     a_1 & c^{\\top}_1 \\\\\n",
    "     0 & A_2\n",
    "     \\end{pmatrix}$, $a_1 \\ne 0$ because $A$ is strictly regular. Continue to apply this procedure to $A_2$ and so futher, we obtained that diagonal elements of $A$ and $A_1$ are not equal to zero. And $A_1$ is strictly regular. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stability of LU \n",
    "\n",
    "Let\n",
    "$A = \\begin{pmatrix}\n",
    "\\varepsilon & 1 & 0\\\\\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{pmatrix}.$ \n",
    "* (5 pts) Find analytically LU decomposition with and without pivoting for the matrix $A$.\n",
    "* (3 pts) Explain, why can the LU decomposition fail to approximate factors $L$ and $U$ for $|\\varepsilon|\\ll 1$ in computer arithmetic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your solution is here\n",
    "- $A = \\begin{pmatrix}\n",
    "\\varepsilon & 1 & 0\\\\\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{pmatrix}\\ = \n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "\\frac{1}{\\varepsilon} & 1 & 0 \\\\\n",
    "0 & \\frac{\\varepsilon}{\\varepsilon-1} & 1\n",
    "\\end{pmatrix}\\\n",
    "\\begin{pmatrix}\n",
    "\\varepsilon & 1 & 0\\\\\n",
    "0 & 1-\\frac{1}{\\varepsilon} & 1 \\\\\n",
    "0 & 0 & \\frac{1}{1-\\varepsilon}\n",
    "\\end{pmatrix}$ - $without \\: pivoting$\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "P = \\begin{pmatrix}\n",
    "0 & 1 & 0\\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\\: - \\: permutation\\: matrix\n",
    "$$\n",
    "$$\n",
    "A_{perm}= PA = \\begin{pmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "\\varepsilon & 1 & 0 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{pmatrix}\\ \n",
    "$$\n",
    "$$\n",
    "    P\\: -\\: orthogonal\\: and\\: simmetric,\\: that's\\: why\\: A=PA_{perm} = \n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 0\\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "\\varepsilon & 1 & 0 \\\\\n",
    "0 & \\frac{1}{1-\\varepsilon} & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 1\\\\\n",
    "0 & 1-\\varepsilon & -\\varepsilon \\\\\n",
    "0 & 0 & \\frac{1}{1-\\varepsilon}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "- Without pivoting we have to devide by the very small number. Computer can recognize number with finite accuracy, and after the limit 1e-16 it consider number as zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Block LU \n",
    "\n",
    "Let $A = \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix}$ be a block matrix. The goal is to solve the linear system\n",
    "\n",
    "$$\n",
    "     \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} = \\begin{bmatrix} f_1 \\\\ f_2 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "* (2 pts) Using block elimination find matrix $S$ and right-hand side $\\hat{f_2}$ so that $u_2$ can be found from $S u_2 = \\hat{f_2}$. Note that the matrix $S$ is called <font color='red'> Schur complement </font> of the block $A_{11}$.\n",
    "* (4 pts) Using Schur complement properties prove that \n",
    "\n",
    "$$\\det(X+AB) = \\det(X)\\det(I+BX^{-1}A), $$\n",
    "\n",
    "\n",
    "where $X$ - nonsingular square matrix.\n",
    "* (4 pts) Let matrix $F \\in \\mathbb{R}^{m \\times n}$ and $G \\in \\mathbb{R}^{n \\times m}$. Prove that \n",
    "\n",
    "$$\\det(I_m - FG) = \\det(I_n - GF).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My solution is here\n",
    "- $$\\begin{bmatrix} A_{21}A_{11}^{-1}A_{11} & A_{21}A_{11}^{-1}A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} = \n",
    "    \\begin{bmatrix} A_{21}A_{11}^{-1}f_1 \\\\ f_2 \\end{bmatrix}\n",
    "$$ \n",
    "$$\n",
    "$$\n",
    "$$\n",
    " \\begin{bmatrix} A_{11} & A_{12} \\\\ 0 & A_{22} - A_{21}A_{11}^{-1}A_{12} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} = \n",
    "    \\begin{bmatrix} f_1 \\\\ f_2 - A_{21}A_{11}^{-1}f_1 \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "    S = A_{22} - A_{21}A_{11}^{-1}A_{12}, \\:\\: \\hat{f_2} = f_2 - A_{21}A_{11}^{-1}f_1\n",
    "$$ \n",
    " \n",
    "- $$ \n",
    "\\det(X+AB) = \\det \\begin{bmatrix} X & -A \\\\ B & I \\end{bmatrix} = \\det(X)\\det(I+BX^{-1}A), \\:\\:\\: where \\:\\:\\: I+BX^{-1}A \\:\\: is \\:\\: Schur \\:\\: complement \\:\\:of \\:\\: X\n",
    "$$\n",
    "- $$\n",
    "rank(FG) = rank(GF) = k \\le \\min(rank(F), rank(G))\n",
    "$$\n",
    "Matrix $FG$ has the same diagonal value as matrix $GF$, that's why consider them in basises where they have diagonal forms.\n",
    "$$\n",
    " \\det(I_m - FG) = \\det(S(I_m-FG)S^{-1}) = \\det(I_m-\\text{diag}(\\lambda_1, \\dots, \\lambda_k)) = \\prod^k_{i=1}(1-\\lambda_i)\n",
    "$$\n",
    "$$\n",
    " \\det(I_n - GF) = \\det(B(I_n-GF)B^{-1}) = \\det(I_n-\\text{diag}(\\lambda_1, \\dots, \\lambda_k)) = \\prod^k_{i=1}(1-\\lambda_i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (QR decomposition) 30 pts\n",
    "\n",
    "### 1. Standard Gram-Schmidt algorithm\n",
    "Our goal is to orthogonalize a system of linearly independent vectors $v_1,\\dots,v_n$.\n",
    "The standard algorithm for this task is the Gram-Schmidt process:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "u_1 &= v_1, \\\\\n",
    "u_2 &= v_2 - \\frac{(v_2, u_1)}{(u_1, u_1)} u_1, \\\\\n",
    "\\dots \\\\\n",
    "u_n &= v_n - \\frac{(v_n, u_1)}{(u_1, u_1)} u_1 - \\frac{(v_n, u_2)}{(u_2, u_2)} u_2 - \\dots - \\frac{(v_n, u_{n-1})}{(u_{n-1}, u_{n-1})} u_{n-1}.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Obtained $u_1, \\dots, u_n$ are orthogonal vectors in exact arithmetics. Then to make the system orthonormal you should divide each of the vectors by its norm: $u_i := u_i/\\|u_i\\|$.\n",
    "The Gram-Schmidt process can be considered as a QR decomposition. Let us show that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (2 pts) Write out what is matrices $Q$ and $R$ obtained in the process above. \n",
    "\n",
    "* (5 pts) Implement in the ```pset2.py``` the described Gram-Schmidt algorithm as a function ```gram_schmidt_qr(A)``` that takes a rectangular matrix ```A``` and outputs ```Q,R```.\n",
    "\n",
    "* (3 pts) Create a square [Vandermonde matrix](https://en.wikipedia.org/wiki/Vandermonde_matrix) $V\\in\\mathbb{R}^{n\\times n},\\ n = 20$ defined by the vector $x$: ```x = np.linspace(0,1,n)``` (components of $x$ are spaced uniformly between 0 and 1). \n",
    "The loss of orthogonality can be described by the following error: $\\|Q^{\\top}Q-I\\|_2$, where $Q^{\\top}Q$ is called a Gram matrix. Compute QR decomposition of the created matrix $V$ with function that you have implemented and calculate error $\\|Q^{\\top}Q-I\\|_2$. Comment on the result.\n",
    "\n",
    "* (5 pts) The observed loss of orthogonality is a problem of this particular algorithm. Luckily, there is [a simple improvement to the algorithm above](https://en.wikipedia.org/wiki/Gram–Schmidt_process#Numerical_stability) that reduces the loss of orthogonality. Implement this modification in the ```pset2.py``` as a function ```modified_gram_schmidt_qr(A)``` such that input and output are similar to ```gram_schmidt_qr(A)```. \n",
    "* (3 pts) Compute QR decomposition of the matrix $V$ from the previous task with the function ```modified_gram_schmidt_qr(A)```.\n",
    "Compute error $\\|Q^{\\top}Q-I\\|_2$. Compare this error to the error obtained with a \"pure\" Gram-Schmidt and comment on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First subproblem (2pts)\n",
    "- $A = [v_1,\\dots,v_n]$  $Q = [u_1, \\dots, u_n]$  $R = \\begin{bmatrix} (v_{1}, u_{1}) & (v_2, u_1) & \\dots &  (v_n, u_1)\\\\\n",
    "                                                        0 & (v_2, u_2) & (v_3, u_2)& \\dots \\\\\n",
    "                                                        \\dots & \\dots & \\dots & \\dots \\\\\n",
    "                                                        \\dots & \\dots & (v_{n-1}, u_{n-1}) &(v_n, u_{n-1})\\\\\n",
    "                                                        0 & \\dots & 0 & (v_n, u_n)\n",
    "                                                        \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart Gram-Schmidt: 9.982976452872656\n",
      "Modified Gram-Schmidt: 0.2685531870664454\n"
     ]
    }
   ],
   "source": [
    "# Implement the functions in the ```pset2.py``` file\n",
    "from pset2 import gram_schmidt_qr\n",
    "from pset2 import modified_gram_schmidt_qr\n",
    "\n",
    "n = 20\n",
    "x = np.linspace(0, 1, n)\n",
    "V = np.ones([n,n])\n",
    "for i in range(1, n):\n",
    "    V[:, i] = x**i\n",
    "\n",
    "Q, R = gram_schmidt_qr(V)\n",
    "print('Standart Gram-Schmidt:',np.linalg.norm(np.dot(Q.transpose(),Q)-np.eye(n), 2))\n",
    "\n",
    "Q_m, R_m = modified_gram_schmidt_qr(V)\n",
    "print('Modified Gram-Schmidt:',np.linalg.norm(np.dot(Q_m.transpose(),Q_m)-np.eye(n), 2))\n",
    "# Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In standart Gram-Schmidt process we fing columns of $Q$ which are orthogonal to columns of $A$. In modified Gram-Schmidt process we find colimns of $Q$ which are orthogonal to previous columns of $Q$, so that this process gives less loss of orthogonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Householder QR (10 pts)\n",
    "\n",
    "* (7 pts) Implement algorithm for computing QR decomposition based on Householder reflections as a function ```householder_qr(A)``` that takes a rectangular matrix ```A``` and outputs ```Q,R```.\n",
    "\n",
    "\n",
    "* (2 pts) Apply it to the Vandermonde matrix $V$ created above. Print out the error $\\|Q^{\\top}Q-I\\|_2$, where $Q$ is given by ```householder_qr(A)```. Compare it to the corresponding results of Gram-Schmidt and modified Gram-Schmidt algorithms and comment on it. \n",
    "\n",
    "\n",
    "\n",
    "* (3 pts) For values of $n = \\{2,25,100,250,500\\}$, create a $B\\in\\mathbb{R}^{n\\times n}$ and an upper triangular matrix $R\\in\\mathbb{R}^{n\\times n}$ both filled with standard normal entries. Use ```numpy``` (or ```scipy```) built-in QR decomposition function to obtain a random orthogonal matrix $Q$ from the decomposition of $B$. Then compute $A = QR$ and apply your Gram-Schmidt and Householder algorithms to find the $Q$ and $R$ factors of $A$ – denoted as $\\hat{Q}$ and $\\hat{R}$. \n",
    "Calculate relative errors\n",
    "$$\\frac{\\|R-\\hat{R}\\|_2}{\\|R\\|_2}, \\frac{\\|Q-\\hat{Q}\\|_2}{\\|Q\\|_2}, \\frac{\\|A-\\hat{Q}\\hat{R}\\|_2}{\\|A\\|_2}$$ \n",
    "for each value of $n$ and for both algorithms. \n",
    "**Note:** scale (multiply corresponding rows/columns by -1) $Q, R,\\hat{Q},\\hat{R}$ such that diagonal elements of $R$ and $\\hat{R}$ be positive.    \n",
    "    * Comment on the relative errors in $Q$ and $R$ (forward error) compared to ones in $QR$ (backward error).\n",
    "    * Comment on the backward error obtained for Gram-Schmidt compared to Householder.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Householder is : 2.5724955796061303e-15\n"
     ]
    }
   ],
   "source": [
    "# Implement the function in the pset2.py file\n",
    "from pset2 import householder_qr\n",
    "\n",
    "# Your code is here\n",
    "n = 20\n",
    "x = np.linspace(0, 1, n)\n",
    "V = np.ones([n,n])\n",
    "for i in range(1, n):\n",
    "    V[:, i] = x**i\n",
    "Q_h, R_h = householder_qr(V)\n",
    "\n",
    "print('Householder is :', np.linalg.norm(np.dot(Q_h.T,Q_h)-np.eye(n), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The error becomes very small in comparison with Gram-Schmidt, because Q is product of orthogonal matrix if Householder product by defenition. It depends only on coputer precision, when Gram-Schmidt depends on condition number of A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = [2, 25, 100, 250, 500]\n",
    "R_error = np.zeros(5)\n",
    "Q_error = np.zeros(5)\n",
    "A_error = np.zeros(5)\n",
    "j = 0\n",
    "for n in N:\n",
    "    B = np.random.randn(n, n)\n",
    "    R = np.tril(np.random.randn(n, n)).T\n",
    "    for i in range(n):\n",
    "        if R[i, i] < 0:\n",
    "            R[i, i] = -R[i, i]\n",
    "    Q, r = np.linalg.qr(B)\n",
    "    A = np.dot(Q,R)\n",
    "    Q_new, R_new = householder_qr(A)\n",
    "    for i in range(n):\n",
    "        if R_new[i, i] < 0:\n",
    "            R_new[i, :] = -R_new[i,:]\n",
    "            Q_new[:, i] = -Q_new[:, i]\n",
    "    R_error[j] = np.linalg.norm(R-R_new, 2)/np.linalg.norm(R, 2)\n",
    "    Q_error[j] = np.linalg.norm(Q-Q_new, 2)/np.linalg.norm(Q, 2)\n",
    "    A_error[j] = np.linalg.norm(A-np.dot(Q_new, R_new), 2)/np.linalg.norm(A, 2)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R - relative error: [1.59602140e-16 1.13571209e-12 7.68953240e-01 1.21548458e+00\n",
      " 1.34979444e+00] \n",
      "\n",
      "Q - relative error: [0.00000000e+00 1.14573318e-11 1.97292346e+00 1.99981043e+00\n",
      " 2.00000000e+00] \n",
      "\n",
      "A - relative error: [1.59602140e-16 9.01636471e-16 2.77618214e-15 6.58699977e-15\n",
      " 1.08578229e-14] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('R - relative error:', R_error, '\\n')\n",
    "print('Q - relative error:', Q_error, '\\n')\n",
    "print('A - relative error:', A_error, '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The forward error is growing, but backward error increases not so rapidly, because algorithm can be slightly different that results in big relative forward error in large scale problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (Word2Vec as Matrix Factorization) 45 pts\n",
    "\n",
    "In this assignment you are supposed to apply SVD to training your own [word embedding model](https://en.wikipedia.org/wiki/Word_embedding) which maps English words to vectors of real numbers.\n",
    "\n",
    "Skip-Gram Negative Sampling (SGNS) word embedding model, commonly known as **word2vec** ([Mikolov et al., 2013](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)), is usually optimized by stochastic gradient descent. However, the optimization of SGNS objective can be viewed as implicit matrix factorization objective as was shown in ([Levy and Goldberg, 2015](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Notation\n",
    "Assume we have a text corpus given as a sequence of words $\\{w_1,w_2,\\dots,w_n\\}$ where $n$ may be larger than $10^{12}$ and $w_i \\in \\mathcal{V}$ belongs to a vocabulary of words $\\mathcal{V}$. A word $c \\in \\mathcal{V}$ is called *a context* of word $w_i$ if they are found together in the text. More formally, given some measure $L$ of closeness between two words (typical choice is $L=2$), a word $c \\in \\mathcal{V}$ is called a context if $c \\in \\{w_{i-L}, \\dots, w_{i-1}, w_{i+1}, \\dots, w_{i+L} \\}$ Let $\\mathbf{w},\\mathbf{c}\\in\\mathbb{R}^d$ be the *word embeddings* of word $w$ and context $c$, respectively. Assume they are specified by the mapping  $\\Phi:\\mathcal{V}\\rightarrow\\mathbb{R}^d$, so $\\mathbf{w}=\\Phi(w)$. The ultimate goal of SGNS word embedding model is to fit a good mapping $\\Phi$.\n",
    "\n",
    "Let $\\mathcal{D}$ be a multiset of all word-contexts pairs observed in the corpus. In the SGNS model, the probability that word-context pair $(w,c)$ is observed in the corpus is modeled as the following distribution:\n",
    "\n",
    "$$\n",
    "P(\\#(w,c)\\neq 0|w,c) = \\sigma(\\mathbf{w}^\\top \\mathbf{c}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^\\top \\mathbf{c})},\n",
    "$$\n",
    "\n",
    "where $\\#(w,c)$ is the number of times the pair $(w,c)$ appears in $\\mathcal{D}$ and $\\mathbf{w}^\\top\\mathbf{c}$ is the scalar product of vectors $\\mathbf{w}$ and $\\mathbf{c}$. Two important quantities which we will also use further are the number of times the word $w$ and the context $c$ appear in $\\mathcal{D}$, which can be computed as\n",
    "\n",
    "$$\n",
    "\\#(w) = \\sum_{c\\in\\mathcal{V}} \\#(w,c), \\quad \\#(c) = \\sum_{w\\in\\mathcal{V}} \\#(w,c).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Optimization objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla word embedding models are trained by maximizing log-likelihood of observed word-context pairs, namely\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} \\#(w,c) \\log \\sigma(\\mathbf{w}^\\top\\mathbf{c}) \\rightarrow \\max_{\\mathbf{w},\\mathbf{c} \\in \\mathbb{R}^d}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip-Gram Negative Sampling approach modifies the objective by additionally minimizing the log-likelihood of random word-context pairs, so called *negative samples*. This idea incorporates some useful linguistic information that some number ($k$, usually $k=5$) of word-context pairs *are not* found together in the corpus which usually results in word embeddings of higher quality. The resulting optimization problem is\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} \\left( \\#(w,c) \\log \\sigma(\\mathbf{w}^\\top\\mathbf{c}) + k \\cdot \\mathbb{E}_{c'\\sim P_\\mathcal{D}} \\log \\sigma (-\\mathbf{w}^\\top\\mathbf{c}) \\right) \\rightarrow \\max_{\\mathbf{w},\\mathbf{c} \\in \\mathbb{R}^d},\n",
    "$$\n",
    "\n",
    "where $P_\\mathcal{D}(c)=\\frac{\\#(c)}{|\\mathcal{D}|}$ is a probability distribution over word contexts from which negative samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Levy and Goldberg, 2015](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf) showed that this objective can be equivalently written as\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} f(w,c) = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} \\left( \\#(w,c) \\log \\sigma(\\mathbf{w}^\\top\\mathbf{c}) + \\frac{k\\cdot\\#(w)\\cdot\\#(c)}{|\\mathcal{D}|} \\log \\sigma (-\\mathbf{w}^\\top\\mathbf{c}) \\right) \\rightarrow \\max_{\\mathbf{w},\\mathbf{c} \\in \\mathbb{R}^d},\n",
    "$$\n",
    "\n",
    "A crucial observation is that this loss function depends only on the scalar product $\\mathbf{w}^\\top\\mathbf{c}$ but not on embedding $\\mathbf{w}$ and $\\mathbf{c}$ separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Matrix factorization problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $|\\mathcal{V}|=m$, $W \\in \\mathbb{R}^{m\\times d}$ and $C \\in \\mathbb{R}^{m\\times d}$ be matrices, where each row $\\mathbf{w}\\in\\mathbb{R}^d$ of matrix $W$ is the word embedding of the corresponding word $w$ and each row $\\mathbf{c}\\in\\mathbb{R}^d$ of matrix $C$ is the context embedding of the corresponding context $c$. SGNS embeds both words and their contexts into a low-dimensional space $\\mathbb{R}^d$, resulting in the word and context matrices $W$ and $C$. The rows of matrix $W$ are typically used in NLP tasks (such as computing word similarities) while $C$ is ignored. It is nonetheless instructive to consider the product $W^\\top C = M$. Viewed this way, SGNS can be described as factorizing an implicit matrix $M$ of dimensions $m \\times m$ into two smaller matrices.\n",
    "\n",
    "Which matrix is being factorized? A matrix entry $M_{wc}$ corresponds to the dot product $\\mathbf{w}^\\top\\mathbf{c}$ . Thus, SGNS is factorizing a matrix in which each row corresponds to a word $w \\in \\mathcal{V}$ , each column corresponds to a context $c \\in \\mathcal{V}$, and each cell contains a quantity $f(w,c)$ reflecting the strength of association between that particular word-context pair. Such word-context association matrices are very common in the NLP and word-similarity literature. That said, the objective of SGNS does not explicitly state what this association metric is. What can we say about the association function $f(w,c)$? In other words, which matrix is SGNS factorizing? Below you will find the answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (theoretical) 5 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve SGNS optimization problem with respect to the $\\mathbf{w}^\\top\\mathbf{c}$ and show that the matrix being factorized is\n",
    "\n",
    "$$\n",
    "M_{wc} = \\mathbf{w}^\\top\\mathbf{c} = \\log \\left( \\frac{\\#(w,c) \\cdot |\\mathcal{D}|}{k\\cdot\\#(w)\\cdot\\#(c)} \\right)\n",
    "$$\n",
    "\n",
    "**Hint:** Denote $x=\\mathbf{w}^\\top\\mathbf{c}$, rewrite SGNG optimization problem in terms of $x$ and solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This matrix is called Shifted Pointwise Mutual Information (SPMI) matrix, as its elements can be written as\n",
    "\n",
    "$$\n",
    "\\text{SPMI}(w,c) = M_{wc} = \\mathbf{w}^\\top\\mathbf{c} = \\text{PMI}(w,c) - \\log k\n",
    "$$\n",
    "\n",
    "and $\\text{PMI}(w,c) = \\log \\left( \\frac{\\#(w,c) \\cdot |\\mathcal{D}|}{\\#(w)\\cdot\\#(c)} \\right)$ is the well-known [pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) of $(w,c)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My proof is here\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} f(w,c) = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} \\left( \\#(w,c) \\log \\sigma(\\mathbf{w}^\\top\\mathbf{c}) + \\frac{k\\cdot\\#(w)\\cdot\\#(c)}{|\\mathcal{D}|} \\log \\sigma (-\\mathbf{w}^\\top\\mathbf{c}) \\right) \\rightarrow \\max_{\\mathbf{w},\\mathbf{c} \\in \\mathbb{R}^d}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{w}^\\top\\mathbf{c} = x\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} f(w,c) = \\sum_{w \\in \\mathcal{V}} \\sum_{c \\in \\mathcal{V}} \\left( \\#(w,c) \\log \\sigma(x) + \\frac{k\\cdot\\#(w)\\cdot\\#(c)}{|\\mathcal{D}|} \\log \\sigma (-x) \\right) \\rightarrow \\max_{\\mathbf{w},\\mathbf{c} \\in \\mathbb{R}^d}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial x} = 0\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial x} =  \\#(w,c) \\frac{\\frac{\\partial\\sigma(x)}{\\partial x}}{\\sigma(x)} + \\frac{k\\cdot\\#(w)\\cdot\\#(c)}{|\\mathcal{D}|} \\frac{\\frac{\\partial \\sigma (-x)}{\\sigma(x)}}{ \\sigma (-x) }\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial\\sigma(x)}{\\partial x} = \\frac{\\exp(-x)}{(1+\\exp(-x))^2} \\: \\, \\:\\frac{\\partial\\sigma(-x)}{\\partial x} = -\\frac{\\exp(x)}{(1+\\exp(x))^2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial x} =  \\#(w,c) \\frac{1}{\\exp(x)+1} - \\frac{k\\cdot\\#(w)\\cdot\\#(c)}{|\\mathcal{D}|} \\frac{\\exp(x)}{ \\exp(x) + 1} = 0\n",
    "$$\n",
    "$$\n",
    "\\exp(x) = \\frac{\\#(w,c)|\\mathcal{D}|}{k\\cdot\\#(w)\\cdot\\#(c)}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{w}^\\top\\mathbf{c} = \\log\\left(\\frac{\\#(w,c)|\\mathcal{D}|}{k\\cdot\\#(w)\\cdot\\#(c)}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (practical) 40 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download dataset [enwik8](http://mattmahoney.net/dc/enwik8.zip) of compressed Wikipedia articles and preprocess raw data with Perl script **main_.pl**. This script will clean all unnecessary symbols, make all words to lowercase, and produce only sentences with words.\n",
    "```\n",
    "wget http://mattmahoney.net/dc/enwik8.zip\n",
    "unzip enwik8.zip\n",
    "mkdir data\n",
    "perl main_.pl enwik8 > data/enwik8.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enwik 8\n",
    "\n",
    "import re\n",
    "file = open(\"data/enwik8.txt\", \"r\")\n",
    "doclist = [line for line in file]\n",
    "docstr = ''.join(doclist)\n",
    "sentences = re.split(r'[.!?]', docstr)\n",
    "sentences = [sentence.split() for sentence in sentences if len(sentence) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['achilles', 'wrath', 'is', 'terrible', 'and', 'he', 'slays', 'many', 'trojan', 'warriors', 'and', 'allies', 'including', 'priam', 's', 'son', 'lycaon', 'whom', 'achilles', 'had', 'previously', 'captured', 'and', 'sold', 'into', 'slavery', 'but', 'who', 'had', 'been', 'returned', 'to', 'troy']\n"
     ]
    }
   ],
   "source": [
    "print (sentences[1249])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Construct the word vocabulary from the obtained sentences which enumerates words which occur more than $r=200$ times in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(sentences, r=200):\n",
    "    vocabulary = {}\n",
    "    temp_vocab = {}\n",
    "    # Your code is here\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if (word in temp_vocab):\n",
    "                temp_vocab[word] += 1\n",
    "            else:\n",
    "                temp_vocab[word] = 1\n",
    "    for word in temp_vocab.keys():\n",
    "        if (temp_vocab[word]>=r):\n",
    "            vocabulary[word] = temp_vocab[word]\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = create_vocabulary(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scan the text corpus with sliding window of size $5$ and step $1$ (which corresponds to $L$=2) and construct co-occurrence word-context matrix $D$ with elements $D_{wc}=\\#(w,c)$. Please, ignore words which occur less than $r=200$ times, but include them into the sliding window. Please, see the graphical illustration of the procedure described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sliding window](sliding_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus_matrix(sentences, vocabulary):\n",
    "    # Your code is here\n",
    "    \n",
    "    words = vocabulary.keys()\n",
    "    corpus_matrix = np.zeros((len(words), len(words)))\n",
    "    word_numbers = {}\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        word_numbers[word] = i\n",
    "        i+=1\n",
    "    for sentence in sentences:\n",
    "        length = len(sentence)\n",
    "        position = 0\n",
    "        for word in sentence:\n",
    "            if (word in words):\n",
    "                L1, L2 = window_size(position, length-1)\n",
    "                for context in sentence[position-L1: position]:\n",
    "                    if (context in words): \n",
    "                        corpus_matrix[word_numbers[word], word_numbers[context]] +=1\n",
    "                        \n",
    "                for context in sentence[position+1: position+L2+1]:\n",
    "                    if (context in words): \n",
    "                        corpus_matrix[word_numbers[word], word_numbers[context]] +=1\n",
    "            position += 1\n",
    "    return corpus_matrix\n",
    "\n",
    "def window_size(current_pos, max_pos):\n",
    "    if current_pos>=2:\n",
    "        L1 = 2\n",
    "    else:\n",
    "        L1 = current_pos\n",
    "    if (max_pos - current_pos >= 2):\n",
    "        L2 = 2\n",
    "    else:\n",
    "        L2 = max_pos - current_pos\n",
    "    return L1, L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = create_corpus_matrix(sentences, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To find good word embeddings, [Levy and Goldberg, 2015](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf) proposed to find rank-$d$ SVD of Shifted Positive Pointwise Mutual Information (SPPMI) matrix\n",
    "\n",
    "$$\n",
    "U \\Sigma V^\\top \\approx \\text{SPPMI},\n",
    "$$\n",
    "\n",
    "where $\\text{SPPMI}(w, c) = \\max\\left(\\text{SPMI}(w, c), 0 \\right)$ and $\\text{SPMI}(w, c)$ is the element of the matrix $\\text{SPPMI}$ at position $(w, c)$.\n",
    "Then use $W=U\\sqrt{\\Sigma}$ as word embedding matrix. Your task is to reproduce their results. Write function constructs $\\text{SPPMI}$ matrix, computes its SVD and produces word-vectors matrix $W$. Pay attention that $\\text{SPPMI}$ matrix is **sparse**!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(D, k, d=200):\n",
    "    # Your code is here\n",
    "    embedding_matrix = np.zeros((D.shape[0], d))\n",
    "    SPPMI = np.zeros((D.shape))\n",
    "    w = np.zeros((D.shape[0], 1))\n",
    "    c = np.zeros((1, D.shape[1]))\n",
    "    w = np.sum(D, axis = 1)\n",
    "    w = w.reshape(D.shape[0], 1)\n",
    "    c = np.sum(D, axis = 0)\n",
    "    c = c.reshape(1, D.shape[1])\n",
    "    size_D = np.sum(D)\n",
    "    SPPMI = np.maximum(np.log(size_D*D)-np.log(np.dot(w, c)*k), 0)\n",
    "    SPPMI = csc_matrix(SPPMI)\n",
    "    u, s, v = svds(SPPMI, d, return_singular_vectors = 'u')\n",
    "    embedding_matrix = np.dot(u, np.diag(np.sqrt(s))) \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mac_Laren\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "k = 5 # negative sampling parameter\n",
    "W = compute_embeddings(D, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write class **WordVectors** using provided template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVectors:\n",
    "    \n",
    "    def __init__(self, vocabulary, embedding_matrix):\n",
    "        self.vocab = vocabulary\n",
    "        self.W = embedding_matrix\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        \n",
    "    def word_vector(self, word):\n",
    "        \"\"\" \n",
    "        Takes word and returns its word vector.\n",
    "        \"\"\"\n",
    "#         Your code is here\n",
    "        i=0\n",
    "        word_number = {}\n",
    "        for word_ in self.vocab.keys():\n",
    "            word_number[word_] = i\n",
    "            i+=1\n",
    "        word_vector = self.W[word_number[word], :]\n",
    "        word_vector = word_vector.reshape(1, len(word_vector))\n",
    "        return word_vector\n",
    "    \n",
    "    def nearest_words(self, word, top_n=10):\n",
    "        \"\"\" \n",
    "        Takes word from the vocabulary and returns its top_n\n",
    "        nearest neighbors in terms of cosine similarity.\n",
    "        \"\"\"\n",
    "#       Your code is here\n",
    "        inv_voc = []\n",
    "        neighbors = []\n",
    "        cos_matrix = cosine_similarity(self.W, WordVectors.word_vector(self, word))\n",
    "        for word_ in self.vocab.keys():\n",
    "            inv_voc.append(word_)\n",
    "        for i in range (11):\n",
    "            top = np.argmax(cos_matrix)\n",
    "            if i != 0:\n",
    "                neighbors.append((inv_voc[int(top)], round(float(cos_matrix[int(top)]),3)))\n",
    "            cos_matrix[int(top)] = 0\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WordVectors(vocab, W)#It was in notebook before my solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = WordVectors(vocab, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('communism', 0.792),\n",
       " ('anarcho', 0.787),\n",
       " ('capitalism', 0.784),\n",
       " ('socialism', 0.752),\n",
       " ('liberalism', 0.727),\n",
       " ('criticisms', 0.705),\n",
       " ('capitalist', 0.662),\n",
       " ('fascism', 0.565),\n",
       " ('anarchist', 0.527),\n",
       " ('marxist', 0.518)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nearest_words(\"anarchism\")#It was in notebook before my solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('communism', 0.792)\n",
      "('anarcho', 0.787)\n",
      "('capitalism', 0.784)\n",
      "('socialism', 0.752)\n",
      "('liberalism', 0.727)\n",
      "('criticisms', 0.705)\n",
      "('capitalist', 0.662)\n",
      "('fascism', 0.565)\n",
      "('anarchist', 0.527)\n",
      "('marxist', 0.518)\n"
     ]
    }
   ],
   "source": [
    "neigh_1 = my_model.nearest_words(\"anarchism\")\n",
    "for x in neigh_1:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ukraine', 0.671),\n",
       " ('russia', 0.629),\n",
       " ('poland', 0.55),\n",
       " ('belarus', 0.538),\n",
       " ('yugoslavia', 0.538),\n",
       " ('romania', 0.517),\n",
       " ('serbia', 0.507),\n",
       " ('austria', 0.5),\n",
       " ('hungary', 0.466),\n",
       " ('bulgaria', 0.43)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nearest_words(\"ussr\")#It was in notebook before my solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ukraine', 0.671)\n",
      "('russia', 0.629)\n",
      "('poland', 0.55)\n",
      "('belarus', 0.538)\n",
      "('yugoslavia', 0.538)\n",
      "('romania', 0.517)\n",
      "('serbia', 0.507)\n",
      "('austria', 0.5)\n",
      "('hungary', 0.466)\n",
      "('bulgaria', 0.43)\n"
     ]
    }
   ],
   "source": [
    "neigh_2 = my_model.nearest_words(\"ussr\")\n",
    "for x in neigh_2:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hop', 0.828),\n",
       " ('hip', 0.817),\n",
       " ('funk', 0.758),\n",
       " ('rock', 0.737),\n",
       " ('punk', 0.706),\n",
       " ('music', 0.676),\n",
       " ('pop', 0.666),\n",
       " ('scene', 0.659),\n",
       " ('band', 0.657),\n",
       " ('jazz', 0.625)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nearest_words(\"rap\")#It was in notebook before my solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hop', 0.828)\n",
      "('hip', 0.817)\n",
      "('funk', 0.758)\n",
      "('rock', 0.737)\n",
      "('punk', 0.706)\n",
      "('music', 0.676)\n",
      "('pop', 0.666)\n",
      "('scene', 0.659)\n",
      "('band', 0.657)\n",
      "('jazz', 0.625)\n"
     ]
    }
   ],
   "source": [
    "neigh_3 = my_model.nearest_words(\"rap\")\n",
    "for x in neigh_3:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculate top 10 nearest neighbours with the corresponding cosine similarities for the words {numerical, linear, algebra} and insert them in the correspoding functions in ```pset2.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = my_model.nearest_words(\"numerical\")\n",
    "linear = my_model.nearest_words(\"linear\")\n",
    "algebra = my_model.nearest_words(\"algebra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('computation', 0.547), ('mathematical', 0.532), ('calculations', 0.499), ('polynomial', 0.485), ('calculation', 0.473), ('practical', 0.46), ('statistical', 0.456), ('symbolic', 0.455), ('geometric', 0.441), ('simplest', 0.438)]\n"
     ]
    }
   ],
   "source": [
    "print(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('differential', 0.759), ('equations', 0.724), ('equation', 0.682), ('continuous', 0.674), ('multiplication', 0.674), ('integral', 0.672), ('algebraic', 0.667), ('vector', 0.654), ('algebra', 0.63), ('inverse', 0.622)]\n"
     ]
    }
   ],
   "source": [
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('geometry', 0.795), ('calculus', 0.73), ('algebraic', 0.716), ('differential', 0.687), ('equations', 0.665), ('equation', 0.648), ('theorem', 0.647), ('topology', 0.634), ('linear', 0.63), ('integral', 0.618)]\n"
     ]
    }
   ],
   "source": [
    "print(algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 (eigenvalues)  45 pts\n",
    "\n",
    "### 1. Theoretical tasks\n",
    "\n",
    "* (5 pts) Prove that normal matrix is Hermitian iff its eigenvalues are real. Prove that normal matrix is unitary iff its eigenvalues satisfy $|\\lambda| = 1$. \n",
    "\n",
    "* (5 pts) The following problem illustrates instability of the Jordan form. Find theoretically the eigenvalues of the perturbed Jordan block:\n",
    "\n",
    "$$\n",
    "    J(\\lambda) = \n",
    "    \\begin{bmatrix} \n",
    "     \\lambda & 1 & & & 0 \\\\ \n",
    "     & \\lambda & 1 & & \\\\ \n",
    "     &  & \\ddots & \\ddots & \\\\ \n",
    "     & & & \\lambda & 1 \\\\ \n",
    "     \\varepsilon & & & & \\lambda  \\\\ \n",
    "    \\end{bmatrix}_{n\\times n}\n",
    "$$\n",
    "\n",
    "Comment how eigenvalues of $J(0)$ are perturbed for large $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical problems\n",
    "- Let x - eigenvector of H - Hermitian matrix\n",
    "$$\n",
    "    (Hx, x) = \\lambda^*(x,x) = (x, Hx) = \\lambda(x,x),\\:\\:\\: if \\:\\: \\lambda^*=\\lambda, \\:\\: then \\: \\:\\lambda\\:-\\:real\n",
    "$$\n",
    "    All normal matrices are diagonalizable. $\\lambda_1, \\dots, \\lambda_n$ are real. $H = Udiag(\\lambda_1, \\dots, \\lambda_n)U^*$, $H^* = Udiag(\\lambda_1^*, \\dots, \\lambda_n^*)U^*$, all $\\lambda$ are real, so $H = H^*$ \n",
    "$$\n",
    "$$\n",
    "Let x - eigenvector of $U$ - unitary matrix, $(Ux,Ux) = |\\lambda|^2(x,x) = (x, x)$, then $|\\lambda|=1$\n",
    "$$\n",
    "$$\n",
    "Let $|\\lambda|=1$ - eigenvalues of $B$, $B$ - normal matrix,  $B = Udiag(\\lambda_1, \\dots, \\lambda_n)U^*$, $BB^* = Udiag(\\lambda_1\\lambda_1^*, \\dots, \\lambda_n\\lambda_n^*)U^* = UIU^* = I$, then $B$ is unitary.\n",
    "\n",
    "-\n",
    "$$ \n",
    "    det(J(\\varepsilon)-\\mu I) = (\\lambda-\\mu)^n + (-1)^{n+1}\\varepsilon = 0\n",
    "$$\n",
    "$$\n",
    "    (\\lambda-\\mu)^n=(-1)^{n}\\varepsilon\n",
    "$$\n",
    "$$\n",
    "    \\mu = \\lambda-\\sqrt[n]{(-1)^{n}\\varepsilon}\n",
    "$$\n",
    "For large $n$ eigenvalues of $J(0)$ will be near the 1 or -1 that depends on $n$ is even or odd, because if $n$ is large then root in power $n$ will be near to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PageRank\n",
    "\n",
    "\n",
    "#### Damping factor importance\n",
    "\n",
    "* (5 pts) Write the function ```pagerank_matrix(G)``` that takes an adjacency matrix $G$ (in both sparse and dense formats) as an input and outputs the corresponding PageRank matrix $A$.\n",
    "\n",
    "* (3 pts) Find PageRank matrix $A$ that corresponds to the following graph: <img src=\"graph.png\" width='250'>\n",
    "What is its largest eigenvalue? What multiplicity does it have?\n",
    "\n",
    "\n",
    "* (5 pts) Implement the power method for a given matrix $A$, an initial guess $x_0$ and a number of iterations ```num_iter```. It should be organized as a function ```power_method(A, x0, num_iter)``` that outputs approximation to eigenvector $x$, eigenvalue $\\lambda$ and history of residuals $\\{\\|Ax_k - \\lambda_k x_k\\|_2\\}$. Make sure that the method conveges to the correct solution on a matrix $\\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}$ which is known to have the largest eigenvalue equal to $3$.\n",
    "\n",
    "\n",
    "* (2 pts) Run the power method for the graph presented above and plot residuals $\\|Ax_k - \\lambda_k x_k\\|_2$ as a function of $k$ for ```num_iter=100``` and random initial guess ```x0```.  Explain the absence of convergence. \n",
    "\n",
    "\n",
    "* (2 pts) Consider the same graph, but with a directed edge that goes from the node 3 to the node 4 being removed. Plot residuals as in the previous task and discuss the convergence. Now, run the power method with ```num_iter=100``` for 10 different initial guesses and print/plot the resulting approximated eigenvectors. Why do they depend on the initial guess?\n",
    "\n",
    "\n",
    "In order to avoid this problem Larry Page and Sergey Brin [proposed](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf) to use the following regularization technique:\n",
    "\n",
    "$$\n",
    "A_d = dA + \\frac{1-d}{N} \\begin{pmatrix} 1 & \\dots & 1 \\\\ \\vdots & & \\vdots \\\\ 1 & \\dots & 1 \\end{pmatrix},\n",
    "$$\n",
    "\n",
    "where $d$ is a small parameter in $[0,1]$ (typically $d=0.85$), which is called **damping factor**, $A$ is of size $N\\times N$. Now $A_d$ is the matrix with multiplicity of the largest eigenvalue equal to 1. \n",
    "Recall that computing the eigenvector of the PageRank matrix, which corresponds to the largest eigenvalue, has the following interpretation. Consider a person who stays in a random node of a graph (i.e. opens a random web page); at each step s/he follows one of the outcoming edges uniformly at random (i.e. opens one of the links). So the person randomly walks through the graph and the eigenvector we are looking for is exactly his/her stationary distribution â€” for each node it tells you the probability of visiting this particular node. Therefore, if the person has started from a part of the graph which is not connected with the other part, he will never get there.  In the regularized model, the person at each step follows one of the outcoming links with probability $d$ OR teleports to a random node from the whole graph with probability $(1-d)$.\n",
    "\n",
    "* (2 pts) Now, run the power method with $A_d$ and plot residuals $\\|A_d x_k - \\lambda_k x_k\\|_2$ as a function of $k$ for $d=0.97$, ```num_iter=100``` and a random initial guess ```x0```.\n",
    "\n",
    "* (5 pts) Find the second largest in the absolute value eigenvalue of the obtained matrix $A_d$. How and why is it connected to the damping factor $d$? What is the convergence rate of the PageRank algorithm when using damping factor?\n",
    "\n",
    "Usually, graphs that arise in various areas are sparse (social, web, road networks, etc.) and, thus, computation of a matrix-vector product for corresponding PageRank matrix $A$ is much cheaper than $\\mathcal{O}(N^2)$. However, if $A_d$ is calculated directly, it becomes dense and, therefore, $\\mathcal{O}(N^2)$ cost grows prohibitively large for  big $N$.\n",
    "\n",
    "\n",
    "* (2 pts) Implement fast matrix-vector product for $A_d$ as a function ```pagerank_matvec(A, d, x)```, which takes a PageRank matrix $A$ (in sparse format, e.g., ```csr_matrix```), damping factor $d$ and a vector $x$ as an input and returns $A_dx$ as an output. \n",
    "\n",
    "* (1 pts) Generate a random adjacency matrix of size $10000 \\times 10000$ with only 100 non-zero elements and compare ```pagerank_matvec``` performance with direct evaluation of $A_dx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the functions in the pset2.py file\n",
    "from pset2 import pagerank_matrix, power_method, pagerank_matvec\n",
    "\n",
    "# Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank Matrix:\n",
      " [[0.  0.  0.5 0.  0. ]\n",
      " [1.  0.  0.5 0.  0. ]\n",
      " [0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.  1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "G = np.zeros((5,5))\n",
    "G[0, 1] = 1\n",
    "G[1, 2] = 1\n",
    "G[2, 1] = 1\n",
    "G[2, 0] = 1\n",
    "G[3, 4] = 1\n",
    "G[4, 3] = 1\n",
    "A = pagerank_matrix(csr_matrix(G))\n",
    "A = A.toarray()\n",
    "print('PageRank Matrix:\\n', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5+0.5j -0.5-0.5j  1. +0.j   1. +0.j  -1. +0.j ]\n",
      "Largest eigenvalue: 1.0 , Multiplicity is 2\n"
     ]
    }
   ],
   "source": [
    "w, v = np.linalg.eig(A)\n",
    "print(w)\n",
    "print('Largest eigenvalue:', round(max(np.abs(w)),2), ', Multiplicity is 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.999999999530459\n"
     ]
    }
   ],
   "source": [
    "#Checking of power_method\n",
    "Checking = np.array([[2, -1], [-1, 2]])\n",
    "x0 = np.array([100, -5]).T\n",
    "x, l, res = power_method(Checking, x0, 10)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#power_method for graph\n",
    "x0 = np.random.randn(5, 1)\n",
    "x_g, l_g, res_g = power_method(A, x0, 100)\n",
    "plt.plot(range(101), res_g)\n",
    "plt.xlabel('Number of iteration')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Power method for PageRank matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power method doesn't converge because of the multiplicity of the largest eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mac_Laren\\Desktop\\NLA\\psets\\pset2.py:130: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  L = np.array(1./G.sum(axis=1))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove (3, 4) node\n",
    "G_new = G\n",
    "G_new[3, 4] = 0\n",
    "A_new = pagerank_matrix(G_new)\n",
    "x_new, l_new, res_new = power_method(A_new, x0, 100)\n",
    "plt.semilogy(range(101), res_new/res_new[0])\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Power method for new PageRank matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5+0.5j -0.5-0.5j  1. +0.j   0. +0.j   0. +0.j ]\n"
     ]
    }
   ],
   "source": [
    "w_new, v_new = np.linalg.eig(A_new.toarray())\n",
    "print(w_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The largest eigenvalue has multiplicity 1, and power method converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector 1 :\n",
      " [[-0.03868726]\n",
      " [-0.07737452]\n",
      " [-0.07737452]\n",
      " [ 0.93076297]\n",
      " [-0.34671307]] \n",
      "\n",
      "Eigenvector 2 :\n",
      " [[-0.15973785]\n",
      " [-0.3194757 ]\n",
      " [-0.3194757 ]\n",
      " [-0.73366917]\n",
      " [ 0.48175089]] \n",
      "\n",
      "Eigenvector 3 :\n",
      " [[-0.16841765]\n",
      " [-0.33683529]\n",
      " [-0.33683529]\n",
      " [ 0.26524267]\n",
      " [ 0.82119778]] \n",
      "\n",
      "Eigenvector 4 :\n",
      " [[0.08444918]\n",
      " [0.16889835]\n",
      " [0.16889835]\n",
      " [0.91100922]\n",
      " [0.32538783]] \n",
      "\n",
      "Eigenvector 5 :\n",
      " [[0.04690127]\n",
      " [0.09380254]\n",
      " [0.09380254]\n",
      " [0.29297359]\n",
      " [0.9457108 ]] \n",
      "\n",
      "Eigenvector 6 :\n",
      " [[-0.09044633]\n",
      " [-0.18089266]\n",
      " [-0.18089266]\n",
      " [-0.94760512]\n",
      " [ 0.16858138]] \n",
      "\n",
      "Eigenvector 7 :\n",
      " [[ 0.32842773]\n",
      " [ 0.65685547]\n",
      " [ 0.65685547]\n",
      " [-0.17090177]\n",
      " [-0.00309901]] \n",
      "\n",
      "Eigenvector 8 :\n",
      " [[ 0.02816072]\n",
      " [ 0.05632144]\n",
      " [ 0.05632144]\n",
      " [-0.99574131]\n",
      " [ 0.03690552]] \n",
      "\n",
      "Eigenvector 9 :\n",
      " [[-0.18271382]\n",
      " [-0.36542763]\n",
      " [-0.36542763]\n",
      " [ 0.76336526]\n",
      " [ 0.34178126]] \n",
      "\n",
      "Eigenvector 10 :\n",
      " [[0.31014424]\n",
      " [0.62028848]\n",
      " [0.62028848]\n",
      " [0.08938447]\n",
      " [0.35539467]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#intial vector\n",
    "for i in range(1, 11):\n",
    "    X0 = np.random.randn(5, 1)\n",
    "    X, L, RES =  power_method(A, X0, 100)\n",
    "    print('Eigenvector', i, ':\\n', X, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power method depends on intial guess because two different eigenvectors can correspond to the similar eigenvalue that has multiplicity 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = 0.97\n",
    "A_d = d*A+(1-d)*np.ones(A.shape)/A.shape[0]\n",
    "x0_d = np.random.randn(A_d.shape[1],1)\n",
    "x_d, l_d, res_d = power_method(A_d, x0_d, 100)\n",
    "plt.plot(range(101), res_d)\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Power Method for damping PageRank matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second eigenvalue of A_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97596773]]\n"
     ]
    }
   ],
   "source": [
    "y = np.random.randn(5, 1)\n",
    "y = y/np.dot(x_d.T.conj(), y)\n",
    "B_d = A_d - l_d*np.dot(x_d, y.T)\n",
    "x_d2, l_d2, res_d2 = power_method(B_d, x_d, 100)\n",
    "print(l_d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The absolute value of second lagrest eigenvalue equal to d\n",
    "$ \\frac{1-d}{N} \\begin{pmatrix} 1 & \\dots & 1 \\\\ \\vdots & & \\vdots \\\\ 1 & \\dots & 1 \\end{pmatrix}$ has rank equal to 1, so that the largest eigenvalue is equal d+\\frac{1-d}{N}, and the second to d\n",
    "The power method for matrix $B = A_d-\\lambda_1x_1y^T$, so that $y^Tx_1 = 1$ helps to find the second largest eigenvalue of $A_d$, where $x_1$ is eigenvector corresponded to largest eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "d = 0.97\n",
    "ls_matrix = np.zeros((N, N))\n",
    "for i in range(100):\n",
    "    ls_matrix[randint(0, N-1), randint(0,N-1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11 s ± 69.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "490 µs ± 2.47 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (d*ls_matrix+(1-d)*np.ones(ls_matrix.shape)/A.shape[0])@np.random.randn(N, 1)\n",
    "ls_matrix = csr_matrix(ls_matrix)\n",
    "%timeit pagerank_matvec(ls_matrix, 0.97, np.random.randn(N, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBLP: computer science bibliography\n",
    "\n",
    "Download the dataset from [here](https://goo.gl/oZVxEa), unzip it and put `dblp_authors.npz`  and `dblp_graph.npz` in the same folder with this notebook. Each value (author name) from `dblp_authors.npz` corresponds to the row/column of the matrix from `dblp_graph.npz`. Value at row `i` and column `j` of the matrix from `dblp_graph.npz` corresponds to the number of times author `i` cited papers of the author `j`. Let us now find the most significant scientists according to PageRank model over DBLP data.\n",
    "\n",
    "* (4 pts) Load the weighted adjacency matrix and the authors list into Python using ```load_dblp(...)``` function. Print its density (fraction of nonzero elements). Find top-10 most cited authors from the weighted adjacency matrix. Now, make all the weights of the adjacency matrix equal to 1 for simplicity (consider only existence of connection between authors, not its weight). Obtain the PageRank matrix $A$ from the adjacency matrix and verify that it is stochastic.\n",
    " \n",
    " \n",
    "* (1 pts) In order to provide ```pagerank_matvec``` to your ```power_method``` (without rewriting it) for fast calculation of $A_dx$, you can create a ```LinearOperator```: \n",
    "```python\n",
    "L = scipy.sparse.linalg.LinearOperator(A.shape, matvec=lambda x, A=A, d=d: pagerank_matvec(A, d, x))\n",
    "```\n",
    "Calling ```L@x``` or ```L.dot(x)``` will result in calculation of ```pagerank_matvec(A, d, x)``` and, thus, you can plug $L$ instead of the matrix $A$ in the ```power_method``` directly. **Note:** though in the previous subtask graph was very small (so you could disparage fast matvec implementation), here it is very large (but sparse), so that direct evaluation of $A_dx$ will require $\\sim 10^{12}$ matrix elements to store - good luck with that (^_<).\n",
    "\n",
    "\n",
    "* (2 pts) Run the power method starting from the vector of all ones and plot residuals $\\|A_dx_k - \\lambda_k x_k\\|_2$  as a function of $k$ for $d=0.85$.\n",
    "\n",
    "\n",
    "* (1 pts) Print names of the top-10 authors according to PageRank over DBLP when $d=0.85$. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import numpy as np\n",
    "def load_dblp(path_auth, path_graph):\n",
    "    G = load_npz(path_graph).astype(float)\n",
    "    with np.load(path_auth) as data: authors = data['authors']\n",
    "    return G, authors\n",
    "G, authors = load_dblp('dblp_authors.npz', 'dblp_graph.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density is: 4.4986518152305776e-05\n"
     ]
    }
   ],
   "source": [
    "# Your code is here\n",
    "print('Density is:', G.count_nonzero()/(G.shape[0]*G.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scott Shenker\n",
      "Andrew Zisserman\n",
      "Hari Balakrishnan\n",
      "Jiawei Han\n",
      "Anil K. Jain\n",
      "Cordelia Schmid\n",
      "Jitendra Malik\n",
      "Ion Stoica\n",
      "David E. Culler\n",
      "David G. Lowe\n"
     ]
    }
   ],
   "source": [
    "#Top 10 cited authors\n",
    "cited = G.sum(axis=0)\n",
    "for i in range (10):\n",
    "    top = np.argmax(cited)\n",
    "    cited[0, int(top)] = 0\n",
    "    print(authors[int(top)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nonzero_indexes = G.nonzero()\n",
    "G[nonzero_indexes] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mac_Laren\\Desktop\\NLA\\psets\\pset2.py:130: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  L = np.array(1./G.sum(axis=1))\n"
     ]
    }
   ],
   "source": [
    "A = pagerank_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininal sum of column in PageRank_Matrix: 0.0\n",
      "Maximal sum of column in PageRank_Matrix: 1.0000000000004\n"
     ]
    }
   ],
   "source": [
    "print('Mininal sum of column in PageRank_Matrix:', np.min(A.sum(axis=0)))\n",
    "print('Maximal sum of column in PageRank_Matrix:', np.max(A.sum(axis=0)))\n",
    "#Error is related to finite accuracy of computer numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If i try to create LinearOperator, I receive memory error. But modified power method takes 10 minutes for 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method_modified(A, x0, d, num_iter): \n",
    "    # enter your code here\n",
    "    x = x0/np.linalg.norm(x0, 2)\n",
    "    res = np.zeros(num_iter+1)\n",
    "    l = (pagerank_matvec(A, d, x)).T.conj().dot(x)\n",
    "    res[0] = np.linalg.norm(pagerank_matvec(A, d, x)-l*x, 2)\n",
    "    for i in range(1,num_iter+1):\n",
    "        x = pagerank_matvec(A, d, x)\n",
    "        x = x/np.linalg.norm(x, 2)\n",
    "        l = (pagerank_matvec(A, d, x)).T.conj().dot(x)\n",
    "        res[i] = np.linalg.norm(pagerank_matvec(A, d, x)-l*x, 2)\n",
    "    return x, l, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.ones([A.shape[0], 1])\n",
    "d = 0.85\n",
    "x_large, l_large, res_large = power_method_modified(A, x0, d, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(range(101), res_large/res_large[0])\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.ylabel('Residual / Residual on First iteration')\n",
    "plt.title('Power Method for Authors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular = np.zeros((x_large.shape))\n",
    "popular = x_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important authors are: \n",
      "\n",
      "Paul J. Besl\n",
      "Alex Waibel\n",
      "David Wagner\n",
      "Oren Etzioni\n",
      "Brad A. Myers\n",
      "William J. Dally\n",
      "Hiroshi Ishii\n",
      "Thomas L. Madden\n",
      "Jerome H. Saltzer\n",
      "Kurt Hornik\n"
     ]
    }
   ],
   "source": [
    "print('The most important authors are: \\n')\n",
    "for i in range (10):\n",
    "    top = popular.argmax()\n",
    "    popular[top] = 0\n",
    "    print(authors[top])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different authors are considered as most cited and most important. But there are some problem with popular, and I don'tunderstand what is it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
